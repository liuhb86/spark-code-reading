# Spark Source code reading (draft)
## Table of contents
1. [Preface](preface.md)
2. Core Spark Workflow
   * [How are DataFrames converted to RDD?](workflow/df2rdd.md)
   * [How are RDDs converted to Job?](workflow/rdd2job.md)
   * [How are jobs and stages scheduled?](workflow/job_schedule.md)
   * [How are tasks scheduled?](workflow/task_schedule.md)
   * [How does executor execute tasks?](workflow/task_execution.md)
   * [How are the results sent back to the application?](workflow/result.md)
3. Standalone Cluster
   * [How does driver programs communicate with master?](cluster/driver_master.md)
   * How does master communicate with worker? (TODO)
   * How does driver communicate with the executors? (TODO)
4. Important Internal Infrastructure
   * [What does BlockManager do?](infrastructure/blockmanager.md)
   * How shuffle works between stages? (TODO)
   * What is inside the cache? (TODO)
   * How are the caches managed? (TODO)
   * How does the recovery work? (TODO)
   * How does broadcast work? (TODO)
   * How does accumulator work? (TODO)
   * How is the object serialized? (TODO)
   * [RPC](infrastructure/rpc.md)
   * [Task Pool](infrastructure/pool.md)
5. Pefromance Optimization
   * How does Spark respect locality? (TODO)
   * What are the physical plan and logical plan? (TODO)
   * What does the query optimizer do? (TODO)
   * How does code generation work? (TODO)
   * How does speculative task work? (TODO)
   * How does out-heap memory work?(TODO)
6. Streaming/Machine Learning (not planned)
7. [Appendix A Minor concepts](appendix/minor_concepts.md)